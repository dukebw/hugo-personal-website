---
title: "Brendan Duke"
type: "page"
layout: "home"
---

 ![Background Image](assets/images/hank-wallpaper.jpg)

 # Brendan Duke
 Machine Learning Engineer

 <div class="container">
     <div class="row">
         <a class="fa-icon fa-icon-2x" href="https://www.facebook.com/brendan.duke.39" title="">
             <i class="fa-brands fa-facebook"></i>
         </a>
         <a class="fa-icon fa-icon-2x" href="https://techhub.social/@brendanduke" title="">
             <i class="fa-brands fa-mastodon"></i>
         </a>
         <a class="fa-icon fa-icon-2x" href="https://scholar.google.com/citations?user=Gd2IGrEAAAAJ" title="">
             <i class="ai ai-google-scholar-square"></i>
         </a>
         <a class="fa-icon fa-icon-2x" href="https://linkedin.com/in/brendan-duke-b3236095" title="">
             <i class="fa-brands fa-linkedin"></i>
         </a>
         <a class="fa-icon fa-icon-2x" href="https://github.com/dukebw" title="">
             <i class="fa-brands fa-github"></i>
         </a>
     </div>
 </div>

 ## About me

 ![Brendan Duke](assets/images/brendan1.jpg)

 I am a software engineer keenly interested in all manner of systems, and a Machine Learning Team Lead at [ModiFace, Inc](https://modiface.com).
 My research interests include machine learning, deep learning, and computer vision.
 At ModiFace I apply deep learning to the beauty tech space to create augmented reality (AR) virtual experiences.

 I had the pleasure of completing my M.A.Sc. at the University of Guelph advised by [Graham Taylor](https://www.gwtaylor.ca/) in the [Machine Learning Research Group (MLRG)](https://www.gwtaylor.ca/).
 My master's thesis focused on [attention and fusion operators in computer vision](https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/21303/Duke_Brendan_202009_MASc.pdf?sequence=6).

 Prior to that I worked at AMD writing firmware for the [AMD Secure Processor](https://www.amd.com/en/technologies/pro-security).

 ## Research

 ### SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation

 ![SSTVOS Architecture](assets/images/sstvos.png)

 **Brendan Duke**, Abdalla Ahmed, Christian Wolf, Parham Aarabi, Graham W. Taylor

 **CVPR 2021 Oral** *(4.3% acceptance rate)*

 [paper](https://arxiv.org/abs/2101.08833) / [code](https://github.com/dukebw/SSTVOS)

 We introduce a Transformer-based approach to video object segmentation (VOS).
 Our method, called Sparse Spatiotemporal Transformers (SST), extracts per-pixel representations for each object in a video using sparse attention over spatiotemporal features.

 ### LOHO: Latent Optimization of Hairstyles via Orthogonalization

 ![LOHO Preview](assets/images/loho.png)

 Rohit Saha, **Brendan Duke**, Florian Shkurti, Graham W. Taylor, Parham Aarabi

 **CVPR 2021**

 [paper](https://arxiv.org/abs/2103.03891) / [code](https://github.com/dukebw/LOHO)

 We propose Latent Optimization of Hairstyles via Orthogonalization (LOHO), an optimization-based approach using GAN inversion to infill missing hair structure details in latent space during hairstyle transfer.
 Using LOHO for latent space manipulation, users can synthesize novel photorealistic images by manipulating hair attributes either individually or jointly, transferring the desired attributes from reference
 hairstyles.

 ### Attention and Fusion of Deep Representations for Computer Vision

 ![MASc Thesis](assets/images/masc-thesis.png)

 **Brendan Duke**

 **M.A.Sc. Thesis**

 [thesis](https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/21303/Duke_Brendan_202009_MASc.pdf?sequence=6)

 In my master's work I investigated attention and multimodal fusion operators.
 I applied these operators to visual question answering (VQA) and video object segmentation (VOS).

 ### Nail Polish Try-On: Realtime Semantic Segmentation of Small Objects for Native and Browser Smartphone AR Applications

 ![Nail Polish Try On](assets/images/nail-polish-try-on.png)

 **Brendan Duke**, Abdalla Ahmed, Edmund Phung, Irina Kezele, Parham Aarabi

 **CVPR 2019 CV for AR/VR Workshop**

 [paper](https://arxiv.org/abs/1906.02222)

 We provide a system for semantic segmentation of small objects that enables nail polish try-on AR applications to run client-side in realtime in native and web mobile applications.
 This work powers a [nail polish brand's virtual try-on experience](https://www.retaildive.com/news/essie-modiface-debut-ar-nail-polish-try-on-tool/595453/).

 ### Lightweight Real-time Makeup Try-on in Mobile Browsers with Tiny CNN Models for Facial Tracking

 ![Tiny CNN](assets/images/tiny-cnn.png)

 Tianxing Li, Zhi Yu, Edmund Phung, **Brendan Duke**, Irina Kezele, Parham Aarabi

 **CVPR 2019 CV for AR/VR Workshop (Oral)**

 [paper](https://arxiv.org/abs/1906.02260)

 We design small models for high accuracy facial alignment.
 The models we propose make use of light CNN architectures adapted to the facial alignment problem for accurate two-stage prediction of facial landmark coordinates from low-resolution output heatmaps.

 ### Generalized Hadamard-Product Fusion Operators for Visual Question Answering

 ![Generalized Hadamard Product Fusion Operators](assets/images/generalized-hadamard.png)

 **Brendan Duke**, Graham W. Taylor

 **Computer and Robot Vision (CRV) 2018 (Best Paper Award)**

 [paper](https://arxiv.org/abs/1803.09374)

 We propose a generalized class of multimodal fusion operators for the task of visual question answering (VQA).
 We identify generalizations of existing multimodal fusion operators based on the Hadamard product, and show that specific non-trivial instantiations of this generalized fusion operator exhibit superior
 performance in terms of OpenEnded accuracy on the VQA task.

 ## Footer

 ![Mashup Icon](assets/images/mashup-icon.svg)
